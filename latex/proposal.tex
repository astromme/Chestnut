\documentclass{article}
\usepackage{fullpage}
\usepackage{apacite}
\usepackage{url}
\usepackage[bottom]{footmisc} % make sure footnote is at bottom of page
\newcommand{\comment}[1]{}

\begin{document}
\title{CS87 Proposal}
\author{Andrew Stromme \& Ryan Carlson}
\date{March 26, 2010}
\maketitle

\section{Introduction}

The General Purpose Graphics Processing Unit (GPGPU) model of programming allows a programmer to use the power of a Graphics Processing Unit (GPU) to help speed up general computation tasks. GPUs are designed to process large amounts of data very quickly and efficiently, but they have a limited instruction set. Where Central Processing Units (CPUs) are the ``jack of all trades'' of computation, GPUs are the specialists. Sophisticated tools like Compute Unified Device Architecture (CUDA) created by Nvidia and the open-source Open Computing Language (OpenCL) are available to facilitate general computation on these devices. This allows for massive speedup when compared against algorithms implemented on single-threaded CPUs. For better or worse, however, programming on a GPU is very different from programming on a CPU for a number of reasons. First, the GPU is optimized for graphics processing and thus has a very different structure. Second, the designers want to tightly couple their languages with existing programming languages to facilitate transition to GPGPU programs. Obviously, these already-existing languages were not designed with GPUs in mind and so some of the paradigms that should be used in GPGPU programming is hidden. Finally, a primary focus of GPGPU language design is to keep it at a low level. The designers want their users to be able to tweak their performance along every possible axis. All of these characteristics form barriers to the casual programmer.

Our goal is to create a simple language that will expose the core concepts of the GPGPU programming paradigm. Since programming on a GPU is different, we feel it is necessary to work with a language that is different. This language will be specifically tuned to shed light on the advantages of using a GPU. Once the programmer has written code in our language, it will be translated into CUDA code and then compiled. Thus our language is an abstraction of and a mapping onto CUDA. Additionally, a high value is being placed on making the language intuitive and above all readable. As a simple heuristic, code should be immediately comprehensible to even a casual programming audience. Less emphasis will be placed on efficiency, though we still anticipate speedups over CPU runtimes. If we can get a casual programmer interested in GPGPU programming, we hope our language gives them the tools to dig deeper and experiment with CUDA or OpenCL.

\section{Related Works}

We can break up designing this project into two broad categories: pedagogy of programming languages and the paradigm presented by CUDA. In other words, we need to equip ourselves with the tools to design {\em a} language, and then we need to figure out what is necessary to design {\em the} language. Since our language aims to be a teaching language, we look towards {\em Scratch}, a graphical programming language developed at the Massachusetts Institute of Technology (MIT), for guidance. Scratch provides an appealing graphical environment aimed at introducing programming to 8-16 year olds. Familiar programming constructs like conditionals and loops are present, but are presented in an intuitive manner. The authors hold that the ``computational thinking'' that programming affords is a valuable tool that should be encouraged but is currently lacking in non-Computer Science curriculum. Most children's digital fluency is defined by ``reading'' but not ``writing.'' The article discusses some of the design decisions that went into the language. To make the language appeal to their target, the authors wanted Scratch to be more tinkerable, meaningful, and social. Additionally, we can think of any programming language as having a ``low floor'' (easy to begin), ``high ceiling'' (ability to become more complex), and ``wide walls'' (support for a diverse range of projects). Scratch appropriately focuses on the low floor and wide walls, arguing that a higher ceiling is outside the scope of a learning language, and if students are interesting in ``raising the ceiling'' they can and should look to more established languages like C or Python \cite{resnick}.

Another interesting paper draws parallels between teaching a second natural language and teaching a first programming language. The authors claim that these processes are not as different as one might expect. While much research has gone into how best to communicate the syntax and semantics contained in a natural language, teaching programming languages is sorely in need of such instruction. Central to that argument is a concentration on writing code over reading it. A large and important part of learning a natural language is an ability to read, digest, and internalize the information being presented. So, the authors write, we must teach our students to read the code as well as write it. We note that this comes as a contrast to the Scratch approach, which focuses on creation. Clearly, both aspects of a language are important. We need a language that is both intuitive to write and readable for others to interpret \cite{robertson}.

We now turn to work regarding CUDA. Most of an undergraduate's computer science training is involved with writing single-threaded, sequential code. Since single-core CPUs are reaching limits on a hardware level, a shift is underway towards multi-core machines. This paper describes how to harness a GPU for general purpose computing using CUDA and how one might implement this into a college curriculum. A high-level overview of the CUDA model is presented along with a sample algorithm that illustrates the usefulness of teaching this new paradigm. The most useful part of this paper was the overview of the process that goes into writing a CUDA program. Given a bird's-eye view of the CUDA model, we can begin to get an idea of how to shape our own language. For example, in CUDA the programmer must decide how many threads will be executed. We would like to hide this detail from the user since it is too low level. Given this kind of big-picture writeup, we can begin to see what may cause problems and what patterns may emerge \cite{tran}.

Finally, we need to consider the paradigm of actually programming for a graphics processor. Converting existing programs from a singly threaded model to the CUDA model can take significant time and experience, partly because of the mechanical conversions needed such as computing array references instead of using loops. hiCUDA is an example of an OpenMP style C preprocessor language that allows the programmer to wrap his singly threaded loops to allow them to be automatically parallelized by CUDA. It was found that examples written with the prototype hiCUDA implementation did not perform significantly worse than the same examples written directly with CUDA. Additionally, the hiCUDA examples were more concise and better fit into existing loop-based computation models that are often present in single threaded programs. However, the language is still based around C using compiler directives and as such may not reflect or emphasize the models that one must internalize to understand GPGPU programming. Still, hiCUDA shows a similar abstraction-minded attitude and gives us an idea of what can be accomplished when building on top of CUDA \cite{han}.

\section{Solution}
Our language will be an abstraction of the GPGPU programming model that is implemented using CUDA. The primary and critical goals are to have a simple, readable language that exposes the GPGPU paradigm. This paradigm will be explored through the creation of 3-5 distinct use-cases (see section \ref{sec:schedule}) and the implementation of these cases in raw CUDA. From the core concepts illuminated by these cases we will create the syntax and keywords of this higher level language and then create a parser/compiler that can translate it to a CUDA program that is executable. An important factor to consider is where our language will fall in the room metaphor discussed by \citeA{resnick} with reference to Scratch. Since this is a teaching language, we want the floor to be very low. Our language should be accessible by a wide audience. Given the short scope of the project, we do not anticipate having very wide walls, but we will keep a mind towards project diversity. Since, given the problem at hand, a high ceiling would be fulfilled by the ability to manipulate low-level details, this will not be a major focus of ours.

We hope to have a number of features present in this language. Since we have not yet explored CUDA in depth, we can make only early approximations of the form the language will take. There will be some concept of a chunk of data as well as a set of data as a whole. Objects or functions will be able to process small parts of this data which will be units upon which parallelization will act. These functions can conceptually be organized into a pipeline which we feel is an important concept with GPGPU programming. The pipeline will process a chunk of data in parallel with other identical functions. We would also like to explore having a toolbox of data manipulation functions such as {\em map}, {\em reduce}, and {\em sort}. This would allow programs to use some pre-defined functions that hide the difficult aspects from the user. To promote the pipeline mentality, inputs and outputs of objects or functions will be connected to one another so that data can flow from some start point (before processing) to some end point (after processing). Finally we hope to design a GUI for this language with the mindset of the MIT Scratch project. Our current structure lends itself well to a graphical environment and if we have the time, we believe a user-friendly graphical interface involving connected drag-and-drop nodes would enhance the user experience.

\section{Experiments}
\label{sec:experiments}
After our language has been developed and prototyped we plan to run a number of experiments comparing its performance to raw CUDA code and to single threaded CPU programs. For each of the 3-5 CUDA use-cases we will implement the given algorithm 3 times: once in our language, once directly in CUDA and once as a normal C/C++ program to be run on the CPU. We expect to see a performance benefit when programs written in our language are compared to single threaded C/C++ implementations but a (hopefully slight) performance loss when compared to handwritten CUDA implementations. We want to perform this series of tests to ensure that we still achiving a performance gain. This is important to us because creating a single threaded CPU-bound application is vastly less complicated and would be preferred if there were no performance difference.

\section{Equipment Needed}
Crucial to this project is the CUDA developer kit from Nvidia and a CUDA-enabled GPU to use this framework. The CS lab computers already have CUDA SDK 2.2 which is sufficent for our work. Additionally, a number of the computers in the lab have new enough graphics cards that support CUDA. Nvidia has just released CUDA SDK 3.0 which, among other things, supports C++ code for the parts that run on the graphics card. If we feel this would help us in writing our language we can look into having it installed on the CS computers but for now it doesn't seem necessary. Our language parser/compiler will be built using GNU Bison and/or Lex. Both are installed on CS computers. If we get to the GUI parts of our project the interfaces will be built using the Qt Toolkit\footnote{\url{http://qt.nokia.com}} which is also already installed on the CS machines. We have investigated MIT Scratch locally but it might be interesting to have a working copy on the lab machines. If we near this part of the project we will address the installation then.

\section{Schedule}
\label{sec:schedule}

\subsubsection*{1: Exploring CUDA with simple projects (March 27)}
\begin{itemize}
  \item The concepts behind writing CUDA programs are new to us. We need some time to explore them by writing small example programs, following tutorials, setting up the cmake buildsystem, and reading about CUDA concepts and workflows. We don't expect that any of these small programs will make large impacts on our use-cases or language but they allow for the crucial experimentation stage to learn CUDA.
  \end{itemize}

\subsubsection*{2: Design \& implement 3-5 use-cases (March 30)}
\begin{itemize}
  \item To gather principles of writing programs for the GPU we will identify and implement (in CUDA), 3-5 example programs/algorithms. The current ideas follow:
    \begin{itemize}
      \item Fluid/Physics Simulation -- this requires some limited interdependence of data as well as a lot of raw computation and a lot of timesteps.
      \item Matrix Operations
      \item Reduce (along an axis/threshold) -- reduce is a common concept when working with large sets of data. It is useful to perform in parallel and requires good synchronization support within CUDA and our language.
      \item Sort -- sorting is also a common time-consuming concept that requires synchronization.
      \item Real-time Stream Processing -- processing small chunks of data at a time and outputting the results while taking new input is something we would like to support.
  \end{itemize}
\end{itemize}

\subsubsection*{3: Abstract overarching principles from use-cases (April 1)}
\begin{itemize}
  \item From these use-cases we will group similar concepts/programming paths and abstract those into language constructs. These concepts need to be able to support the group of use-cases that we have identified, so they will set the bare minimum of what our language is able to be used for.
\end{itemize}
  
\subsubsection*{4: Design language around core principles (April 5)}
\begin{itemize}
  \item We expect this (and the above) to be an important and a difficult step. As explained previously, we are aiming to have a `low floor'; ideally our language would start off with a very simple complete example. From there we can add more complexity to the language to allow for more problems but it is important to keep the simplicity, even if it means hiding away features that could enhance performance. This is also the stage where we would really like to have input from other people. We plan to be finished with this milestone in time for the mid-way presentation so that we can incorporate feedback and review our decisions.
\end{itemize}
 
\subsubsection*{5: Implement parsing and compiling of our language (April 19)}
\begin{itemize}  
  \item This is where GNU bison and the more algorithmic part of the project happens. At the end of this stage we will have a program or process that takes a program written in our language and compiles or interprets it into CUDA code that can then be compiled to run on the GPU. Again the focus is on enabling our use-cases and that will be considered sufficient if we run into time/scope issues.
\end{itemize}

\subsubsection*{6: Experiments (April 23)}
\begin{itemize}
  \item After we have a completed language and parser/compiler we will run the experiments that were detailed in section \ref{sec:experiments}. This is also the time to work on the final presentation and paper. 
\end{itemize}

\subsubsection*{7: Design GUI or repeat from step 2 (as time allows)}
\begin{itemize}
  \item Assuming that the language is implemented as we currently think it will be, the GUI will be a way of expressing the core ideas in GPU programming. Specifically, it is planned to have a canvas where objects that perform data processing can be placed and later hooked up in a visual manner. This will emphasize the flow of data through one processing `filter' and into others based on the connections made. We are basing some our ideas off of the MIT Scratch visual development environment and we hope that our GUI could provide a simple introduction to GPU programming. Alternatively (or in parallel), if we want to expand the language we can write more use-cases, identify more abstractions, and add them into the language.
\end{itemize}

\section{Conclusion}

GPUs are very powerful devices. But to use them for general purpose computation we need to jump through hoops to use CUDA. Additionally, CUDA is prohibitively complicated for many programmers interested in speeding up their computation but not necessarily learning the ins and outs of a GPU. To ease the transition from CPU programming to GPU programming we aim to create a new language that simplifies the process. We expect to identify high level patterns and express them in a way that exposes the paradigms that a programmer would need to effectively use the GPU. While we do anticipate slowdowns from handwritten CUDA code, we hope to create and reinforce good GPGPU coding habits that will allow our users to move onto more extensive projects in the future.


\bibliographystyle{apacite}
\bibliography{references}

\end{document}
