%\documentclass{article}
\documentclass[twocolumn]{article}
\usepackage{fullpage}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{url}
\usepackage{fixltx2e} % so that 'starred' figures aren't out of order with 'non-starred' figures
\usepackage[bottom]{footmisc} % make sure footnote is at bottom of page
\newcommand{\comment}[1]{}

\usepackage{float}
\newfloat{Algorithm}{h!}{}{}
\newfloat{Code Snippet}{h!}{}{}

% program-related commands
\usepackage{program}
\renewcommand{\|}{\origbar} % use this instead of '|' because program package redefines '|'
\renewcommand{\WHILE}{\mbox{{\bf while} }\tab}
\renewcommand{\FOR}{\mbox{{\bf for} }\tab}
\renewcommand{\IF}{\mbox{{\bf if} }\tab}
\newcommand{\IN}{\mbox{ {\bf in} }}

\newcommand{\code}[1]{\texttt{#1}}

\begin{document}
\title{Chestnut: Simplifying General Purpose Graphics Processing}
\author{Andrew Stromme \& Ryan Carlson}
\date{May 10, 2010}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction (RC)}

Say why GPGPU is cool but difficult. We have provided an easier way to deal with it. With us, you get the performance gains without the steep learning curve.

\section{Related Works (RC)}

Basically just plop our annotated bibliography in here.

\section{General Purpose Graphics Processing}

\subsection{Structure of Graphics Processing Unit}

A graphics processing unit is a dedicated piece of hardware separate from the CPU. It was originally designed for graphics processing where each pixel is run through a series of transformations and filters before it is shown on the screen. However, the massively parallel architecture of the GPU is now being used for more general purpose programming. 

Modern GPUs are structured with dozens of individual processing units organized into blocks on the card. Each of these blocks has access to a small amount of fast block-shared memory (similar in speed to the cache on a CPU) and the vastly slower but much larger GPU main memory. Unlike CPUs, GPUs can not assign and run different threads of computation simultaneously on their many processing units. Instead, they run a single process (called a kernel) on every unit. These kernels are able to access both types of memory and perform their computations in parallel. The programmer is responsible for writing this kernel, as well as for designing the way in how threads will be assigned data. This can be a complex task that requires some low level knowledge on how the GPU is designed as well as knowledge of special extensions to a programming language (e.g. CUDA or OpenCL) that can tell the GPU what to do.

\subsection{Paradigm/Data Flow}

GPUs lend themselves to certain types of programming, and these are not always the same as what traditional parallel models offer. For chestnut we have focused on a single paradigm that allows for significant and semi-automatic parallelization. This model is data oriented and focuses on the interactions between functions and data. Large chunks of data are assumed, such as large 2d arrays where each element in the array is a scalar value. Functions are written to perform the same operation on each element of data with no ordering constraints. This means that the operation can be applied to each element in any order, and more importantly means that the operations can be applied in parallel. This model of programming maps quite nicely onto the core parts of GPU programming. A single program can be written as a kernel and each running instance of that kernel can operate on a small chunk of the overall data.

\subsection{Tools}

There are a number of tools available to interface with the GPU. Two we have chosen are CUDA and Thrust.

\subsubsection{CUDA}

Compute Unified Device Architecture (CUDA) is a system developed by NVidia for performing general purpose computations on the GPU. CUDA is a series of extensions to C along with a specialized compiler. This results in a very low level language where the programmer must know about the GPU to program for it. Because of the extensions to C and amount of fine-grained control that CUDA offers code written in it ends up being verbose and difficult to understand for someone who has not learned about how graphics cards work. This creates an enormous learning curve for aspiring GPU programmers.

\subsubsection{Thrust (RC)}

Much more C++-y. Easier to grasp. More like programming for CPU but still need to know some stuff about GPU

\subsubsection{Thrust Functions (RC)}

We might want an overview of thrust functions here. Might also want that in Translating Chestnut to Thrust

\section{Chestnut}

\subsection{Overview}

Chestnut is a graphical environment for parallel programming. It is composed of a graphical frontend, an intermediate language and a compiler that translates the intermediate language into thrust C++ code. The main point of entry for users is imagined to be the Chestnut GUI, with the simple code underlying this to be a small but more complicated step towards actual thrust code. Chestnut is based on the data-oriented programming model that was explained earlier. This is enforced through the gui and through the limited syntax offered by the underlying program.

\subsection{Target Audience}

Chestnut is meant to be a relatively simple introduction to parallel GPU programming. We expect little to no experience with C++ and see two categories of users with this type of knowledge. The first group is computer science/programming students who have not had any exposure or introduction to GPU programming before. The second group is non computer science programmers who could benefit from parallelizing their computations. Examples of the latter might be other natural science researchers who have written number-crunching programs in scripting languages who have parallelizable algorithms.

With both of these cases the learning curve can be too steep to encourage these programmers to learn about GPU programming. With the underlying chestnut code we are interested in having a similar syntax to python or javascript, where the code is similar to C but without some of the extra syntax such as namespaces, headers vs source files, includes and other complexities. We hope that a person with some knowledge of programming and with a problem could use Chestnut to write a basic solution to this problem.

\subsection{Target Applications}

At this point Chestnut is targeted towards embarrassingly parallel problems. We reason that there are a vast number of embarrassingly parallel problems out there that have not been written to take advantage of the GPUs because of the learning curve associated with GPU programming. Those are our target problems. Additionally, because the target audience is not advanced computer science programmers we are not convinced that the extra complexity that would be needed by offering things like more fine-grained synchronization, lower level kernel specification and control over how blocks of threads are distributed is warranted.

\subsection{Goals}

With both the target audience and the target applications in mind we have identified a few important goals for Chestnut. Primarily it should expose the data-focused model that can be translated to the GPU easily. This can be done by imposing limitations on the gui and on the core language syntax. Secondly we want Chestnut to be modular. This means separating the gui interface from the underlying language, and providing a compiler for this underlying language that could be changed in the future to not depend on Thrust or CUDA should either become eclipsed by other GPU programming environments. Chestnut needs to be discoverable. The gui frontend and its visual and drag and drop interface is a direct result from this, where the user can see how things are supposed to be connected. Lastly we are still interested in achieving a speedup when compared to the CPU. Although Chestnut is not about the fastest possible runtime on the GPU compared to other GPU programs we still want it to be faster than running the same computations on the CPU because even with chestnut there is still a learning curve to working on the GPU.

\section{Chestnut Frontend (AS)}

The Chestnut frontend is designed with the data-centric programming model in mind. It is composed of a canvas upon which objects can be placed and connected together to represent the dataflow within a program.

\subsection{Primitives}

The frontend has three main types of objects, of which two are data containers. The simplest data container is a \code{value}, composed of just a single scalar. \code{Values} are used primarily for the second input to a map function or the result calculated by a reduction function. \code{DataBlocks} are data containers that contain multidimensional data. Currently, only 2d arrays of arbitrary dimensions are implemented, but this could be expanded to three dimensions. Lastly there are \code{functions} which operate on the two data containers. \code{Functions} are well specified and strongly typed; for example, the map function requires two inputs: one DataBlock and either another DataBlock or a Value. The map function then outputs a DataBlock. Functions (such as map and reduce) can optionally accept an operation type which takes two scalars and combines them (for example + or *). With these three types of primitive objects and the connections between them we think many embarrassingly parallel problems can be expressed in Chestnut code.

\subsection{Interface Concepts}

\begin{figure}[h!]
  \centering
    \includegraphics[width=100pt]{simplegui}
  \caption{A sample program in the chestnut GUI.}
\end{figure}

With Chestnut one of the main goals was to have a discoverable interface. We've taken a number of steps towards this end. Firstly, each class of objects has a consistent and unique shape. \code{Functions} are rounded rectangles, \code{DataBlocks} are sharp-cornered rectangles and \code{Values} are triangles. This gives a the user a visual reference to the type of the object he is looking at rather than having to parse and understand some text. Objects can have inputs and outputs, known as \code{sinks} and \code{sources}. A sink corresponds to an input. It can accept data from some source. A \code{source} is like a fountain of data, produced by some object and available to connect to an arbitrary number of sinks. Continuing with the theme of a discoverable interface, sources and sinks have shapes to represent how they can be connected; circles can only be connected to other circles, triangles to triangles and so on. Similarly, sinks are differentiated from sources by a darker interior color. A sink can not be connected to another sink, nor can a source be connected to another source. It is possible to have a sink accept multiple different types of sources. For example, the print function can take either a DataBlock or a Value. This is represented by having both a triangle and a circle next to each other. To help the user create acceptable connections between objects, the Chestnut frontend specifically prevents the user from doing thinks that are impossible, such as connecting a source and a sink of incompatible types or connecting two sources to one sink.

The drag and drop paradigm is central to the Chestnut GUI. Objects are placed on the canvas by dragging them from the left toolbar, connections are made and destroyed by drags from the respective sinks and sources, and objects can be rearranged by dragging them around the canvas. We decided on this drag and drop interface because of the goal of a discoverable frontend. 

The Chestnut frontend forces the data-centric GPU model that we illustrated earlier because of the limitations enforced with connections and the high level atomic functions such as sort, reduce, and map. Sort and reduce are both predefined functions with readily available parallel solutions, such as those present in Thrust. Map enforces our model because it operates on each chunk of the data and performs the same operation to each chunk.


\subsection{Translate GUI to Chestnut Code (RC)}

Visit each node. Each node knows its contribution. Variable Declarations and Function calls.

\section{Chestnut Backend (RC)}

Once the GUI to Chestnut translation is finished, we have Chestnut code output. In this section we discuss the process that brings our Chestnut code to executable object code.

\subsection{Process}

%Lex tokenizes, Yacc accepts sequences of tokens. From Yacc we call helper functions which write Thrust code to disk. Compile that code using nvcc
The translation from Chestnut to executable is a four step process. First, we use Flex\footnote{An open-source version of Lex, found at \\ \url{http://flex.sourceforge.net/}.} to tokenize the Chestnut code. For each valid word in the language, a token is created. For example, if Flex reads the word \code{map} it outputs the \code{TOKMAP} token. While Flex can return just a token without any extra context, it also has the ability to recognize and then save the input in a string or integer and pass that information along as well. In this case, one might have the variable \code{var1} which gets mapped to the {\em identifier} token \code{ID} and additionally saves the string \code{"var1"} to pass along to the next stage. Every valid word or character in the file (including braces, parentheses, etc.) must be tokenized to be accepted and passed along. If a token is not found, Flex will exit with a syntax error. This provides a simple but effective first level of error checking for our code.

As Flex tokenizes the file, it passes each token along to Bison\footnote{The GNU version of Yacc, found at \\ \url{http://gnu.org/software/bison/}.} for processing. Bison generates an LALR(1) (one token Look-Ahead LR) or a GLR (generalized LR) parser. Using very simple regular expressions, Bison generates code that analyzes each token and matches it to predefined acceptable sequences of tokens. For example, suppose the input code for a reduction was \code{"result~=~reduce(data)"}\footnote{See section \ref{sec:specifications} for a full description of syntax}. The resulting sequence of acceptable tokens to check for would be \code{"ID~ASSIGN~TOKREDUCE~LPAREN~ID~RPAREN"}. Once a valid sequence of tokens is identified, we gather the appropriate information (variable names, operators, parameters) and pass them into a utility function (part of a utility class) that takes care of writing all the necessary Thrust code to disk. Once Thrust code has been written it can be compiled to object code using the CUDA compiler, \code{nvcc}.

The utility class knows what files we eventually want to write to, keeps a symbol table, and has all the necessary functions to write appropriate Thrust code. We have broken each file into four general regions: headers (\code{\#includes}), function declarations, the \code{main} function, and function definitions. Each region is represented as an STL vector of strings. Thus, any header files we want to include in a given file or code we want to write to \code{main} get stored as entries in their respective vectors until the Chestnut code is finished being parsed. Once our parser reaches the end of the file, we execute a single write to disk.

The symbol table is implemented as an STL vector of \code{symbol\_entry} structs. A \code{symbol\_entry} is a simple container for four fields. The first is the name of the function or variable. The second is that object's type, either \code{int} or \code{float} at present (see section \ref{sec:specifications} for a complete discussion of supported types). The third field is the category of the entry. It can be either a \code{FUNCTION} or two different variable types. If the variable is a single value, we assign the category \code{VARIABLE\_SCALAR}. If the variable is a vector (or DataBlock, in the frontend terminology) we assign it \code{VARIABLE\_VECTOR}. Finally, each entry has a scope. This field is not currently being used and is by default set to zero. 

\subsection{Specifications}
\label{sec:specifications}

%Support ints, floats. Functions: map, reduce, sort, print, read, write. Ask Tia if we should put specifications here or in an appendix or what.
We currently support two basic variable types, two variable categories, and seven default functions. Here we discuss them and specify each of their uses. This section will introduce the reader to basic Chestnut syntax and give the reader a sense of the level of abstraction used.

At this early stage, the only data types we support are standard C++ \code{int} and \code{float}. Considering our target audience and what we anticipate them using Chestnut for, we believe that in an overwhelming number of cases these basic number types will be sufficient. Users will be acting primarily on large numerical datasets and our language absolutely supports that. In the future, we would like to implement more default types and allow users to define their own types, described in section \ref{sec:future}. 

Before a function is called, variables used by that function must be defined. As discussed earlier, variables can be either vectors or scalars. If a vector is going to be assigned data before being used in a function, it must be initialized using a \code{foreach} loop or a \code{read} command, discussed in section \ref{sec:iofunctions}. Otherwise, if data is going to be used as the result of a function, we must still declare it, but need not specify anything except its type, name, and category. To declare a variable in this way, the general syntax is
\begin{center}
  \code{<type> variableName <category>;\footnote{Angle bracket notation to indicate there a defined set of choices for the given identifier.}}
\end{center}

Chestnut currently has seven functions that operate on data: \code{map}, \code{reduce}, and \code{sort} all manipulate the data in some way; \code{foreach}, \code{read}, \code{write}, and \code{print} comprise the Input/Output interface of our language. The general syntax for a function call in Chestnut is
\begin{align*}
  \code{result } &\code{= functionName(} \\ &\code{$param_1,\;\ldots, \;param_k,$ } \\ &\code{inputData);}
\end{align*}
The result of the operation is always stored in a variable (either a scalar or vector) to be used later. Every function also operates on some block of data. These two specifications enforces the data-centric model of programming. Note that it is easy to modify data in place by setting both the result and input to the same variable. Each $param_i$ is an extra parameter that specifies some option of the function. There can be zero or more such parameters. 

\subsubsection{Manipulator Functions}

Let's consider the \code{map} function, the most complex of the default functions. A \code{map} takes a block of data and applies the same modification to every element. For example, we could add 2 to every element in an array. Our \code{map} also works as a convolution operator, applying an operator to corresponding elements in two arrays. Formally, given two 2-dimensional arrays \code{A,B} convolved into a resulting array \code{C}, each with indices \code{i,j}, the resulting array would have the property \code{C[i][j]~=~A[i][j]~+~B[i][j]} for all \code{i,j}. The result of a \code{map} is a vector. The first parameter is the operator (e.g.\ \code{"+"}). The second parameter can either be a single value (e.g.\ \code{"2"}) or a data block. The last parameter is, as always, the input data that will be mapped over. So, if the end user wants to modify a data block \code{inputData} by adding 2 to every element the function call would be
\begin{center}
  \code{inputData = map(+, 2, inputData);}
\end{center}
If instead the user wants to convolve two blocks of data, \code{input1} and \code{input2}, using the multiplication operator and store the result in a third variable \code{output}, the call would be
\begin{center}
  \code{output = map(*, input1, input2);}
\end{center}

The \code{reduce} function accumulates every element of a data block using a specified operator and stores the value in a scalar. For example, a user could use the function to take the sum of every element in an array. The function takes only two parameters, an operator and an input vector. The output is a scalar. Using the example from before, to sum over a data block \code{input} and store the result in the scalar \code{reduced}, we have the syntax
\begin{center}
  \code{reduced = reduce(+, input);}
\end{center}

The \code{sort} function sorts a block of data according to the given comparator. The output is always a data block. The first parameter is the comparator to use (e.g.\ \code{"<"}) while the second is the data to be sorted. Suppose a user wanted to sort a block of data \code{input} in descending order and wanted to store the result in that same variable, the syntax is
\begin{center}
  \code{input = sort(>, input);}
\end{center}

We see that each of the manipulator functions Chestnut offers takes a vector as input, performs an operation on every element and returns some value to be stored in another variable. We note that these functions can be strung together into long sequences of maps, reduces, and sorts. Indeed, we anticipate much of the value of Chestnut to arise from the ability to sequence functions in a pipeline to efficiently compute results.

\subsubsection{Input/Output Functions}
\label{sec:iofunctions}

To initialize a vector, Chestnut offers two options, one of which is the \code{foreach} construct. This is a simplified for-loop construction that traverses every element of the vector and allows the user to create a formula to dictate what value is stored in each cell. The general syntax for a \code{foreach} declaration is
\begin{align*}
  \code{<type>}& \code{ variableName numRows numCols } \\ &\code{foreach ($ForeachExpression$);}
\end{align*}
Every $ForeachExpression$ starts with \code{value =} and then some right-hand side expression. The \code{value} keyword is shorthand for the current index of the data block in the for loop. Thus if the progress of the loop had reached $currentRow$, $currentCol$, then \code{value} would correspond to \code{array[$currentRow$][$currentCol$]}.

The right-hand side of the equation can be any arithmetic expression (e.g.\ 2+4) combined with a set of reserved words. Note that these words are not reserved outside of this context, so a user oblivious of these rules would not be in danger of name conflict errors. The user can reference the current row or column using the \code{row} and \code{col} keywords, respectively. To reference the total rows or total columns a vector has we use \code{maxrows} and \code{maxcols} keywords, respectively. Finally, users can use the keyword \code{rand} to generate a random number. Since this function invokes the C++ $rand()$ function, this will be an integer between 0 and the maximum random number. This offers the most ability for the user to customize his or her random number. 

So, to fill a 10x10 vector of random real numbers between 0 and 1, the full statement would be
\begin{align*}
  \code{float } &\code{data 10 10 } \\ &\code{foreach (rand/RAND\_MAX);}
\end{align*}

Chestnut also allows its users to read data from disk and write data to disk. We use a very clear, simple syntax to read and write files. The first line contains the number rows in the data, then the number of columns. After this the data is listed in a space-separated format. Recall from above that data reads are called only when variables are declared, so the current syntax follows the declaration pattern. In the future we may want to allow data reads at any time. To read from a file \code{"infile"} and store it in a vector \code{data} of integers, we have the syntax
\begin{center}
  \code{int data read("infile");}
\end{center}

The output functions have a different syntax from other functions. To write a block of data, \code{outdata}, to a file, \code{outfile}, the code in Chestnut would be
\begin{center}
  \code{write(outdata, "outfile");}
\end{center}

Similarly, Chestnut provides a function to pint the contents of a data block to standard output. The function takes the rows and columns of the data into account when printing, printing a newline character before starting each new row. To print a data block \code{outdata}, one uses the syntax
\begin{center}
  \code{print outdata;}
\end{center}

The input and output functions Chestnut provides allows the user to view progress in between a series of computations and allows the user to take blocks of data from disk and write them out for storage. When dealing with enormous blocks of data, it seems that reading and writing to disk will be most useful. Still, for benchmarking and various other operations, the \code{foreach} construct will also be useful.

\subsection{Sample Program}

%Do we want to show some samples? Use verbatim!

We have provided in-depth specifications of Chestnut code but have not yet given an example of a full program written in the language. Here we take the opportunity to detail a program written in Chestnut code from start to finish, given in Code Snippet \ref{code:fullprog}. 

First, we initialize \code{input1} and \code{input2} with a random number and data from file, respectively. We then need to declare two vectors, \code{sorted1} and \code{sorted2}. Below the declarations, we sort the initial vectors into their sorted analogues, the first in ascending order, the second in descending order. To get a peak at the computation in progress, we print out both vectors.

Once the data are sorted, we want to convolve over the vectors using the \code{"*"} operator and store them in \code{mapped}, which we then write out to the file \code{"outputdata"}. Finally, we reduce over a sum and print out the result, which is stored in \code{reduced}. This sample program shows the ease with which a user can quickly populate and operate on sets of data. There is also a clear paradigm at work, moving data through functions and storing the results in more data.

\begin{Code Snippet}
\begin{verbatim}
1   float input1 100 100 foreach 
            (value = rand/RAND_MAX);
    float input2 read ("inputdata");

5   float sorted1 vector;
    float sorted2 vector;
    sorted1 = sort(<, input1);
    sorted2 = sort(>, input2);

10  print sorted1;
    print sorted2;

    float mapped vector;
    mapped = map(*, sorted1, sorted2);
15  write (mapped, "outputdata");

    float reduced scalar;
    reduced = reduce(+, mapped);

20  print reduced;
\end{verbatim}
\caption{Sample Chestnut code for a program that adds two sorted vectors together, then sums over their mapped result.}
\label{code:fullprog}
\end{Code Snippet}


\subsection{Translating Chestnut Code to Thrust}

Talk about the assumptions we need to make (when/where memory is allocated), some optimizations (\code{constant\_iterators}), the basic Thrust functions used.

\section{Experiments (RC)}

Run both qualitative experiments -- compare code samples -- and quantitative experiments with runtimes. We show that, subjectively, our code is easier to read, if less powerful. BUT!\ runtimes are very similar.

\subsection{Qualitative}

Compare Chestnut to Thrust to CUDA

\subsection{Quantitative}

Runtimes.

\section{Future Work}
\label{sec:future}

\subsection{Custom Functions}

A significant limitation with the current Chestnut implementation is that it doesn't support the creation of custom functions from within Chestnut code or from the GUI. This complicates the use of Chestnut for applications which have some inter-dependence of data. One example of such an application is Conway's Game of Life \footnote{\url{http://en.wikipedia.org/wiki/Conway's_Game_of_Life}} which requires knowledge of the 8 neighboring squares to calculate the game state for any given square (TODO: Figure out citing). Custom functions would need significant limits on how they could access memory to ensure that the data-centric GPU model is followed, but we think that they are possible. A custom function would have a limited syntax and would be able to assign the values to each bucket based on the value at that bucket and the values of other nearby or arbitrary buckets. A sample syntax for custom functions could look like the following

\begin{Code Snippet}
\begin{verbatim}
(TODO: Talk to ryan about this!)
function average(Input in, Output out) {
    value = above + below + left + right;
    value = value / 4;
}
\end{verbatim}
\end{Code Snippet}

where the specific keywords \code{above, below, left, right} correspond to the values in the array at those positions relative to the current bucket and the keyword \code{value} represents the value in the output array of the current bucket.

\subsection{Custom DataTypes}

Chestnut currently supports integers and real values (floats), but both of these are primitive datatypes. It would be nice to support more complex datatypes consisting of the primitive types. In the case of sorting this allows for finding a specific entry by sorting on some subfield.

TODO: insert array that shows this?

\subsection{More Predefined Functions/Data Types}

Doubles, pairs, c style data structures?

\subsection{Refine GUI}

As features are added to the Chestnut language it is important to continue to find ways to have them cleanly map into the GUI. Custom functions should appear alongside predefined functions and should follow the same semantics for advertising their available inputs and outputs as sinks and sources. The GUI also currently lacks any way of saving or loading a workspace. It would also be important to streamline the build process. Currently it takes quite a few steps and it should be more of a one click process if the user is unfamiliar with the different parts that make up the Chestnut system.

\subsection{For Loops}


\end{document}

